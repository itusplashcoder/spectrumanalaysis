name: Deploy to Databricks

on:
  push:
    branches:
      - master

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install databricks-cli

    - name: Deploy script to Databricks
      env:
        DATABRICKS_HOST: ${{secrets.DBRX_INSTANCE}}
        DATABRICKS_TOKEN: ${{secrets.DBRX_TOKEN}}
      run: |
        # Configure databricks-cli
        databricks configure --token --host $DATABRICKS_HOST --token $DATABRICKS_TOKEN

        # Upload your script to DBFS
        databricks fs cp path/to/your_script.py dbfs:/path/to/your_script.py

        # Run the script as a Databricks job
        JOB_ID=$(databricks jobs create --json '{"name": "MyJob", "new_cluster": {"spark_version": "7.3.x-scala2.12", "num_workers": 2, "node_type_id": "Standard_DS3_v2"}, "spark_python_task": {"python_file": "dbfs:/path/to/your_script.py"}}' | jq -r '.job_id')
        databricks jobs run-now --job-id $JOB_ID
